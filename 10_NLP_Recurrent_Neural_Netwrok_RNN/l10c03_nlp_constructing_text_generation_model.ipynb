{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "punL79CN7Ox6"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_ckMIh7O7s6D"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph5eir3Pf-3z"
      },
      "source": [
        "# Constructing a Text Generation Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Uhzt6vVIB2"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c03_nlp_constructing_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c03_nlp_constructing_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GbGfr_oLCat"
      },
      "source": [
        "Using most of the techniques you've already learned, it's now possible to generate new text by predicting the next word that follows a given seed word. To practice this method, we'll use the [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHK2CYygXom"
      },
      "source": [
        "## Import TensorFlow and related functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2LmLTREBf5ng"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmLTO_dpgge9"
      },
      "source": [
        "## Get the Dataset\n",
        "\n",
        "As noted above, we'll utilize the [Song Lyrics dataset](https://www.kaggle.com/mousehead/songlyrics) on Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4Bf5FVHfganK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu1BTzMIS1oy"
      },
      "source": [
        "## **First 10 Songs**\n",
        "\n",
        "Let's first look at just 10 songs from the dataset, and see how things perform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmb9rGaAUDO-"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "Let's perform some basic preprocessing to get rid of punctuation and make everything lowercase. We'll then split the lyrics up by line and tokenize the lyrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2AVAvyF_Vuh5"
      },
      "outputs": [],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "apcEXp7WhVBs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'you': 1, 'i': 2, 'and': 3, 'a': 4, 'me': 5, 'the': 6, 'is': 7, 'my': 8, 'to': 9, 'ma': 10, 'it': 11, 'of': 12, 'im': 13, 'your': 14, 'love': 15, 'so': 16, 'as': 17, 'that': 18, 'in': 19, 'andante': 20, 'boomaboomerang': 21, 'make': 22, 'on': 23, 'oh': 24, 'for': 25, 'but': 26, 'new': 27, 'bang': 28, 'its': 29, 'be': 30, 'like': 31, 'know': 32, 'now': 33, 'how': 34, 'could': 35, 'youre': 36, 'sing': 37, 'never': 38, 'no': 39, 'chiquitita': 40, 'can': 41, 'we': 42, 'song': 43, 'had': 44, 'good': 45, 'youll': 46, 'she': 47, 'just': 48, 'girl': 49, 'again': 50, 'will': 51, 'take': 52, 'please': 53, 'let': 54, 'am': 55, 'eyes': 56, 'was': 57, 'always': 58, 'cassandra': 59, 'blue': 60, 'time': 61, 'dont': 62, 'were': 63, 'return': 64, 'once': 65, 'then': 66, 'sorry': 67, 'cryin': 68, 'over': 69, 'feel': 70, 'ever': 71, 'believe': 72, 'what': 73, 'do': 74, 'go': 75, 'all': 76, 'out': 77, 'think': 78, 'every': 79, 'leave': 80, 'look': 81, 'at': 82, 'way': 83, 'one': 84, 'music': 85, 'down': 86, 'our': 87, 'give': 88, 'learn': 89, 'more': 90, 'us': 91, 'would': 92, 'there': 93, 'before': 94, 'when': 95, 'with': 96, 'feeling': 97, 'play': 98, 'cause': 99, 'away': 100, 'here': 101, 'have': 102, 'yes': 103, 'baby': 104, 'get': 105, 'didnt': 106, 'see': 107, 'did': 108, 'closed': 109, 'realized': 110, 'crazy': 111, 'world': 112, 'lord': 113, 'shes': 114, 'kind': 115, 'without': 116, 'if': 117, 'touch': 118, 'strong': 119, 'making': 120, 'such': 121, 'found': 122, 'true': 123, 'stay': 124, 'together': 125, 'thought': 126, 'come': 127, 'they': 128, 'sweet': 129, 'tender': 130, 'sender': 131, 'tune': 132, 'humdehumhum': 133, 'gonna': 134, 'last': 135, 'leaving': 136, 'sleep': 137, 'only': 138, 'saw': 139, 'tell': 140, 'hes': 141, 'her': 142, 'sound': 143, 'tread': 144, 'lightly': 145, 'ground': 146, 'ill': 147, 'show': 148, 'life': 149, 'too': 150, 'used': 151, 'darling': 152, 'meant': 153, 'break': 154, 'end': 155, 'yourself': 156, 'little': 157, 'dumbedumdum': 158, 'bedumbedumdum': 159, 'youve': 160, 'dumbbedumbdumb': 161, 'bedumbbedumbdumb': 162, 'by': 163, 'theyre': 164, 'alone': 165, 'misunderstood': 166, 'day': 167, 'dawning': 168, 'some': 169, 'wanted': 170, 'none': 171, 'listen': 172, 'words': 173, 'warning': 174, 'darkest': 175, 'nights': 176, 'nobody': 177, 'knew': 178, 'fight': 179, 'caught': 180, 'really': 181, 'power': 182, 'dreams': 183, 'weave': 184, 'until': 185, 'final': 186, 'hour': 187, 'morning': 188, 'ship': 189, 'gone': 190, 'grieving': 191, 'still': 192, 'pain': 193, 'cry': 194, 'sun': 195, 'try': 196, 'face': 197, 'something': 198, 'sees': 199, 'makes': 200, 'fine': 201, 'who': 202, 'mine': 203, 'leaves': 204, 'walk': 205, 'hand': 206, 'well': 207, 'about': 208, 'things': 209, 'slow': 210, 'theres': 211, 'talk': 212, 'why': 213, 'up': 214, 'lousy': 215, 'packing': 216, 'ive': 217, 'gotta': 218, 'near': 219, 'keeping': 220, 'intention': 221, 'growing': 222, 'taking': 223, 'dimension': 224, 'even': 225, 'better': 226, 'thank': 227, 'god': 228, 'not': 229, 'somebody': 230, 'happy': 231, 'question': 232, 'smile': 233, 'mean': 234, 'much': 235, 'kisses': 236, 'around': 237, 'anywhere': 238, 'advice': 239, 'care': 240, 'use': 241, 'selfish': 242, 'tool': 243, 'fool': 244, 'showing': 245, 'boomerang': 246, 'throwing': 247, 'warm': 248, 'kiss': 249, 'surrender': 250, 'giving': 251, 'been': 252, 'door': 253, 'burning': 254, 'bridges': 255, 'being': 256, 'moving': 257, 'though': 258, 'behind': 259, 'are': 260, 'must': 261, 'sure': 262, 'stood': 263, 'hope': 264, 'this': 265, 'deny': 266, 'sad': 267, 'quiet': 268, 'truth': 269, 'heartaches': 270, 'scars': 271, 'dancing': 272, 'sky': 273, 'shining': 274, 'above': 275, 'hear': 276, 'came': 277, 'couldnt': 278, 'everything': 279, 'back': 280, 'long': 281, 'waitin': 282, 'cold': 283, 'chills': 284, 'bone': 285, 'youd': 286, 'wonderful': 287, 'means': 288, 'special': 289, 'smiles': 290, 'lucky': 291, 'fellow': 292, 'park': 293, 'holds': 294, 'squeezes': 295, 'walking': 296, 'hours': 297, 'talking': 298, 'plan': 299, 'easy': 300, 'gently': 301, 'summer': 302, 'evening': 303, 'breeze': 304, 'grow': 305, 'fingers': 306, 'soft': 307, 'light': 308, 'body': 309, 'velvet': 310, 'night': 311, 'soul': 312, 'slowly': 313, 'shimmer': 314, 'thousand': 315, 'butterflies': 316, 'float': 317, 'put': 318, 'rotten': 319, 'boy': 320, 'tough': 321, 'stuff': 322, 'saying': 323, 'need': 324, 'anymore': 325, 'enough': 326, 'standing': 327, 'creep': 328, 'felt': 329, 'cheap': 330, 'notion': 331, 'deep': 332, 'dumb': 333, 'mistake': 334, 'entitled': 335, 'another': 336, 'beg': 337, 'forgive': 338, 'an': 339, 'feels': 340, 'hoot': 341, 'holler': 342, 'mad': 343, 'under': 344, 'heel': 345, 'holy': 346, 'christ': 347, 'deal': 348, 'sick': 349, 'tired': 350, 'tedious': 351, 'ways': 352, 'aint': 353, 'walkin': 354, 'cutting': 355, 'tie': 356, 'wanna': 357, 'into': 358, 'eye': 359, 'myself': 360, 'counting': 361, 'pride': 362, 'unright': 363, 'neighbours': 364, 'ride': 365, 'burying': 366, 'past': 367, 'peace': 368, 'free': 369, 'sucker': 370, 'street': 371, 'singing': 372, 'shouting': 373, 'staying': 374, 'alive': 375, 'city': 376, 'dead': 377, 'hiding': 378, 'their': 379, 'shame': 380, 'hollow': 381, 'laughter': 382, 'while': 383, 'crying': 384, 'bed': 385, 'pity': 386, 'believed': 387, 'lost': 388, 'from': 389, 'start': 390, 'suffer': 391, 'sell': 392, 'secrets': 393, 'bargain': 394, 'playing': 395, 'smart': 396, 'aching': 397, 'hearts': 398, 'sailing': 399, 'father': 400, 'sister': 401, 'reason': 402, 'linger': 403, 'deeply': 404, 'future': 405, 'casting': 406, 'shadow': 407, 'else': 408, 'fate': 409, 'bags': 410, 'thorough': 411, 'knowing': 412, 'late': 413, 'wait': 414, 'watched': 415, 'harbor': 416, 'sunrise': 417, 'sails': 418, 'almost': 419, 'slack': 420, 'cool': 421, 'rain': 422, 'deck': 423, 'tiny': 424, 'figure': 425, 'rigid': 426, 'restrained': 427, 'filled': 428, 'whats': 429, 'wrong': 430, 'enchained': 431, 'own': 432, 'sorrow': 433, 'tomorrow': 434, 'hate': 435, 'shoulder': 436, 'best': 437, 'friend': 438, 'rely': 439, 'broken': 440, 'feather': 441, 'patch': 442, 'walls': 443, 'tumbling': 444, 'loves': 445, 'blown': 446, 'candle': 447, 'seems': 448, 'hard': 449, 'handle': 450, 'id': 451, 'thinking': 452, 'went': 453, 'house': 454, 'hardly': 455, 'guy': 456, 'closing': 457, 'front': 458, 'emptiness': 459, 'he': 460, 'disapeared': 461, 'his': 462, 'car': 463, 'stunned': 464, 'dreamed': 465, 'lifes': 466, 'part': 467, 'move': 468, 'feet': 469, 'pavement': 470, 'acted': 471, 'told': 472, 'lies': 473, 'meet': 474, 'other': 475, 'guys': 476, 'stupid': 477, 'blind': 478, 'smiled': 479, 'took': 480, 'said': 481, 'may': 482, 'couple': 483, 'men': 484, 'them': 485, 'brother': 486, 'joe': 487, 'seeing': 488, 'lot': 489, 'him': 490, 'nice': 491, 'sitting': 492, 'sittin': 493, 'memories': 494}\n",
            "495\n"
          ]
        }
      ],
      "source": [
        "# Read the dataset from csv - just first 10 songs for now\n",
        "dataset = pd.read_csv('tmp/songdata.csv', dtype=str)[:10]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus)\n",
        "\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9x68iN_X6FK"
      },
      "source": [
        "### Create Sequences and Labels\n",
        "\n",
        "After preprocessing, we next need to create sequences and labels. Creating the sequences themselves is similar to before with `texts_to_sequences`, but also including the use of [N-Grams](https://towardsdatascience.com/introduction-to-language-models-n-gram-e323081503d9); creating the labels will now utilize those sequences as well as utilize one-hot encoding over all potential output words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QmlTsUqfikVO"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length\n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Zsmu3aEId49i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32\n",
            "97\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29\n",
            "   4]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29   4\n",
            " 287]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# Check out how some of our data is being stored\n",
        "# The Tokenizer has just a single index per word\n",
        "print(tokenizer.word_index['know'])\n",
        "print(tokenizer.word_index['feeling'])\n",
        "# Input sequences will have multiple indexes\n",
        "print(input_sequences[5])\n",
        "print(input_sequences[6])\n",
        "# And the one hot labels will be as long as the full spread of tokenized words\n",
        "print(one_hot_labels[5])\n",
        "print(one_hot_labels[6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1TAJMlmfO8r"
      },
      "source": [
        "### Train a Text Generation Model\n",
        "\n",
        "Building an RNN to train our text generation model will be very similar to the sentiment models you've built previously. The only real change necessary is to make sure to use Categorical instead of Binary Cross Entropy as the loss function - we could use Binary before since the sentiment was only 0 or 1, but now there are hundreds of categories.\n",
        "\n",
        "From there, we should also consider using *more* epochs than before, as text generation can take a little longer to converge than sentiment analysis, *and* we aren't working with all that much data yet. I'll set it at 200 epochs here since we're only use part of the dataset, and training will tail off quite a bit over that many epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G1YXuxIqfygN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "62/62 [==============================] - 3s 9ms/step - loss: 6.0514 - accuracy: 0.0318\n",
            "Epoch 2/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 5.4509 - accuracy: 0.0399\n",
            "Epoch 3/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 5.3666 - accuracy: 0.0373\n",
            "Epoch 4/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 5.3117 - accuracy: 0.0399\n",
            "Epoch 5/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 5.2412 - accuracy: 0.0424\n",
            "Epoch 6/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 5.1694 - accuracy: 0.0404\n",
            "Epoch 7/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 5.1056 - accuracy: 0.0404\n",
            "Epoch 8/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 5.0441 - accuracy: 0.0429\n",
            "Epoch 9/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 4.9843 - accuracy: 0.0570\n",
            "Epoch 10/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 4.9230 - accuracy: 0.0742\n",
            "Epoch 11/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 4.8581 - accuracy: 0.0651\n",
            "Epoch 12/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 4.7898 - accuracy: 0.0721\n",
            "Epoch 13/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 4.7048 - accuracy: 0.0797\n",
            "Epoch 14/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 4.6155 - accuracy: 0.0923\n",
            "Epoch 15/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 4.5250 - accuracy: 0.1029\n",
            "Epoch 16/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 4.4368 - accuracy: 0.1075\n",
            "Epoch 17/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 4.3488 - accuracy: 0.1186\n",
            "Epoch 18/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 4.2564 - accuracy: 0.1327\n",
            "Epoch 19/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 4.1777 - accuracy: 0.1433\n",
            "Epoch 20/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 4.0947 - accuracy: 0.1761\n",
            "Epoch 21/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 4.0171 - accuracy: 0.1917\n",
            "Epoch 22/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 3.9333 - accuracy: 0.2099\n",
            "Epoch 23/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.8523 - accuracy: 0.2270\n",
            "Epoch 24/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.7710 - accuracy: 0.2397\n",
            "Epoch 25/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 3.7008 - accuracy: 0.2477\n",
            "Epoch 26/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.6323 - accuracy: 0.2755\n",
            "Epoch 27/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.5655 - accuracy: 0.2841\n",
            "Epoch 28/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.4926 - accuracy: 0.2916\n",
            "Epoch 29/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.4302 - accuracy: 0.2987\n",
            "Epoch 30/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.3626 - accuracy: 0.3133\n",
            "Epoch 31/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 3.2979 - accuracy: 0.3214\n",
            "Epoch 32/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 3.2300 - accuracy: 0.3360\n",
            "Epoch 33/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.1722 - accuracy: 0.3396\n",
            "Epoch 34/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 3.1245 - accuracy: 0.3507\n",
            "Epoch 35/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 3.0564 - accuracy: 0.3683\n",
            "Epoch 36/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.9985 - accuracy: 0.3794\n",
            "Epoch 37/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.9370 - accuracy: 0.3865\n",
            "Epoch 38/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.8968 - accuracy: 0.3885\n",
            "Epoch 39/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.8541 - accuracy: 0.4006\n",
            "Epoch 40/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.8045 - accuracy: 0.4132\n",
            "Epoch 41/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.7544 - accuracy: 0.4268\n",
            "Epoch 42/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.7075 - accuracy: 0.4344\n",
            "Epoch 43/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 2.6457 - accuracy: 0.4470\n",
            "Epoch 44/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.5910 - accuracy: 0.4687\n",
            "Epoch 45/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.5512 - accuracy: 0.4667\n",
            "Epoch 46/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.5147 - accuracy: 0.4687\n",
            "Epoch 47/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.4762 - accuracy: 0.4733\n",
            "Epoch 48/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.4287 - accuracy: 0.4839\n",
            "Epoch 49/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.3830 - accuracy: 0.4955\n",
            "Epoch 50/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.3438 - accuracy: 0.5025\n",
            "Epoch 51/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.3044 - accuracy: 0.5101\n",
            "Epoch 52/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.2717 - accuracy: 0.5166\n",
            "Epoch 53/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.2537 - accuracy: 0.5257\n",
            "Epoch 54/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.1998 - accuracy: 0.5333\n",
            "Epoch 55/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.1636 - accuracy: 0.5358\n",
            "Epoch 56/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.1281 - accuracy: 0.5505\n",
            "Epoch 57/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.1043 - accuracy: 0.5494\n",
            "Epoch 58/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.0451 - accuracy: 0.5676\n",
            "Epoch 59/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.0177 - accuracy: 0.5701\n",
            "Epoch 60/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.9900 - accuracy: 0.5757\n",
            "Epoch 61/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.9754 - accuracy: 0.5737\n",
            "Epoch 62/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.9229 - accuracy: 0.5822\n",
            "Epoch 63/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 1.8804 - accuracy: 0.6009\n",
            "Epoch 64/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.8485 - accuracy: 0.6060\n",
            "Epoch 65/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.8150 - accuracy: 0.6155\n",
            "Epoch 66/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.7890 - accuracy: 0.6241\n",
            "Epoch 67/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.7592 - accuracy: 0.6271\n",
            "Epoch 68/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.7287 - accuracy: 0.6352\n",
            "Epoch 69/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.7124 - accuracy: 0.6342\n",
            "Epoch 70/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 1.6722 - accuracy: 0.6514\n",
            "Epoch 71/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.6420 - accuracy: 0.6584\n",
            "Epoch 72/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.6292 - accuracy: 0.6635\n",
            "Epoch 73/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.6072 - accuracy: 0.6660\n",
            "Epoch 74/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.5794 - accuracy: 0.6741\n",
            "Epoch 75/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.5635 - accuracy: 0.6720\n",
            "Epoch 76/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.5582 - accuracy: 0.6786\n",
            "Epoch 77/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.5107 - accuracy: 0.6877\n",
            "Epoch 78/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.4820 - accuracy: 0.6902\n",
            "Epoch 79/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.4579 - accuracy: 0.7038\n",
            "Epoch 80/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.4392 - accuracy: 0.6973\n",
            "Epoch 81/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.4455 - accuracy: 0.7008\n",
            "Epoch 82/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.4264 - accuracy: 0.6958\n",
            "Epoch 83/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.3945 - accuracy: 0.7059\n",
            "Epoch 84/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 1.3673 - accuracy: 0.7170\n",
            "Epoch 85/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.3385 - accuracy: 0.7205\n",
            "Epoch 86/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.3110 - accuracy: 0.7306\n",
            "Epoch 87/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.2901 - accuracy: 0.7270\n",
            "Epoch 88/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.2739 - accuracy: 0.7326\n",
            "Epoch 89/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.2587 - accuracy: 0.7427\n",
            "Epoch 90/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.2413 - accuracy: 0.7422\n",
            "Epoch 91/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.2223 - accuracy: 0.7503\n",
            "Epoch 92/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.1981 - accuracy: 0.7598\n",
            "Epoch 93/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.2083 - accuracy: 0.7538\n",
            "Epoch 94/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.2025 - accuracy: 0.7518\n",
            "Epoch 95/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.2213 - accuracy: 0.7427\n",
            "Epoch 96/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.2704 - accuracy: 0.7175\n",
            "Epoch 97/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.2038 - accuracy: 0.7386\n",
            "Epoch 98/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.1374 - accuracy: 0.7629\n",
            "Epoch 99/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.1257 - accuracy: 0.7603\n",
            "Epoch 100/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.0942 - accuracy: 0.7750\n",
            "Epoch 101/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.0760 - accuracy: 0.7760\n",
            "Epoch 102/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.0666 - accuracy: 0.7815\n",
            "Epoch 103/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 1.0621 - accuracy: 0.7755\n",
            "Epoch 104/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.0398 - accuracy: 0.7820\n",
            "Epoch 105/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.0115 - accuracy: 0.7916\n",
            "Epoch 106/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.9976 - accuracy: 0.7876\n",
            "Epoch 107/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.9813 - accuracy: 0.7972\n",
            "Epoch 108/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.9642 - accuracy: 0.8002\n",
            "Epoch 109/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.9518 - accuracy: 0.8052\n",
            "Epoch 110/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.9419 - accuracy: 0.8047\n",
            "Epoch 111/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.9302 - accuracy: 0.8078\n",
            "Epoch 112/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.9344 - accuracy: 0.8027\n",
            "Epoch 113/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.9203 - accuracy: 0.8037\n",
            "Epoch 114/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.9191 - accuracy: 0.7967\n",
            "Epoch 115/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.9239 - accuracy: 0.7972\n",
            "Epoch 116/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.9205 - accuracy: 0.7997\n",
            "Epoch 117/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.8858 - accuracy: 0.8037\n",
            "Epoch 118/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.8715 - accuracy: 0.8184\n",
            "Epoch 119/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.8671 - accuracy: 0.8138\n",
            "Epoch 120/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.8501 - accuracy: 0.8199\n",
            "Epoch 121/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.8427 - accuracy: 0.8184\n",
            "Epoch 122/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.8289 - accuracy: 0.8219\n",
            "Epoch 123/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.8172 - accuracy: 0.8209\n",
            "Epoch 124/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.8076 - accuracy: 0.8254\n",
            "Epoch 125/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.7933 - accuracy: 0.8285\n",
            "Epoch 126/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.7889 - accuracy: 0.8330\n",
            "Epoch 127/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.7699 - accuracy: 0.8385\n",
            "Epoch 128/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.7618 - accuracy: 0.8411\n",
            "Epoch 129/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.7546 - accuracy: 0.8391\n",
            "Epoch 130/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.7460 - accuracy: 0.8446\n",
            "Epoch 131/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.7382 - accuracy: 0.8426\n",
            "Epoch 132/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.7319 - accuracy: 0.8486\n",
            "Epoch 133/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.7226 - accuracy: 0.8502\n",
            "Epoch 134/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.7170 - accuracy: 0.8486\n",
            "Epoch 135/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.7123 - accuracy: 0.8441\n",
            "Epoch 136/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.7049 - accuracy: 0.8502\n",
            "Epoch 137/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.6941 - accuracy: 0.8557\n",
            "Epoch 138/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6964 - accuracy: 0.8507\n",
            "Epoch 139/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.7138 - accuracy: 0.8401\n",
            "Epoch 140/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.7074 - accuracy: 0.8436\n",
            "Epoch 141/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6941 - accuracy: 0.8491\n",
            "Epoch 142/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6660 - accuracy: 0.8562\n",
            "Epoch 143/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.6609 - accuracy: 0.8552\n",
            "Epoch 144/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.6798 - accuracy: 0.8481\n",
            "Epoch 145/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6521 - accuracy: 0.8577\n",
            "Epoch 146/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.6335 - accuracy: 0.8592\n",
            "Epoch 147/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6233 - accuracy: 0.8582\n",
            "Epoch 148/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6287 - accuracy: 0.8597\n",
            "Epoch 149/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6243 - accuracy: 0.8618\n",
            "Epoch 150/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6100 - accuracy: 0.8592\n",
            "Epoch 151/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6019 - accuracy: 0.8633\n",
            "Epoch 152/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5976 - accuracy: 0.8623\n",
            "Epoch 153/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5915 - accuracy: 0.8643\n",
            "Epoch 154/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5822 - accuracy: 0.8683\n",
            "Epoch 155/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5769 - accuracy: 0.8663\n",
            "Epoch 156/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5976 - accuracy: 0.8607\n",
            "Epoch 157/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.6380 - accuracy: 0.8512\n",
            "Epoch 158/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6065 - accuracy: 0.8587\n",
            "Epoch 159/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5818 - accuracy: 0.8618\n",
            "Epoch 160/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.5650 - accuracy: 0.8678\n",
            "Epoch 161/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5542 - accuracy: 0.8683\n",
            "Epoch 162/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.5461 - accuracy: 0.8734\n",
            "Epoch 163/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.5378 - accuracy: 0.8718\n",
            "Epoch 164/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5283 - accuracy: 0.8774\n",
            "Epoch 165/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5234 - accuracy: 0.8754\n",
            "Epoch 166/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5416 - accuracy: 0.8744\n",
            "Epoch 167/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5302 - accuracy: 0.8713\n",
            "Epoch 168/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5362 - accuracy: 0.8718\n",
            "Epoch 169/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5161 - accuracy: 0.8799\n",
            "Epoch 170/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5043 - accuracy: 0.8814\n",
            "Epoch 171/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.4988 - accuracy: 0.8824\n",
            "Epoch 172/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.4901 - accuracy: 0.8850\n",
            "Epoch 173/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.4850 - accuracy: 0.8840\n",
            "Epoch 174/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.4809 - accuracy: 0.8824\n",
            "Epoch 175/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.4763 - accuracy: 0.8875\n",
            "Epoch 176/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.4706 - accuracy: 0.8845\n",
            "Epoch 177/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.4670 - accuracy: 0.8829\n",
            "Epoch 178/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.4655 - accuracy: 0.8835\n",
            "Epoch 179/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.4583 - accuracy: 0.8870\n",
            "Epoch 180/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.4569 - accuracy: 0.8880\n",
            "Epoch 181/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.4581 - accuracy: 0.8870\n",
            "Epoch 182/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.4602 - accuracy: 0.8850\n",
            "Epoch 183/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.4606 - accuracy: 0.8855\n",
            "Epoch 184/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.4586 - accuracy: 0.8865\n",
            "Epoch 185/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5720 - accuracy: 0.8522\n",
            "Epoch 186/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.4976 - accuracy: 0.8749\n",
            "Epoch 187/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.4786 - accuracy: 0.8794\n",
            "Epoch 188/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.4600 - accuracy: 0.8925\n",
            "Epoch 189/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.4497 - accuracy: 0.8875\n",
            "Epoch 190/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.4390 - accuracy: 0.8905\n",
            "Epoch 191/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.4827 - accuracy: 0.8764\n",
            "Epoch 192/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.4519 - accuracy: 0.8875\n",
            "Epoch 193/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.4311 - accuracy: 0.8920\n",
            "Epoch 194/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.4251 - accuracy: 0.8935\n",
            "Epoch 195/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.4170 - accuracy: 0.8930\n",
            "Epoch 196/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.4098 - accuracy: 0.8971\n",
            "Epoch 197/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.4056 - accuracy: 0.8961\n",
            "Epoch 198/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.3994 - accuracy: 0.8971\n",
            "Epoch 199/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.3971 - accuracy: 0.8940\n",
            "Epoch 200/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.3929 - accuracy: 0.8971\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=200, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXVFpoREhV6Y"
      },
      "source": [
        "### View the Training Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aeSNfS7uhch0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rAgRpxYhjpB"
      },
      "source": [
        "### Generate new lyrics!\n",
        "\n",
        "It's finally time to generate some new lyrics from the trained model, and see what we get. To do so, we'll provide some \"seed text\", or an input sequence for the model to start with. We'll also decide just how long of an output sequence we want - this could essentially be infinite, as the input plus the previous output will be continuously fed in for a new output word (at least up to our max sequence length)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DC7zfcgviDTp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "im feeling chills me to the bone leaving at an sailing sailing so care so nice gone and rotten even better better bedumbedumdum soul meant realized think hand crazy sucker eyes eyes better throwing hand stuff think stuff brother pain break better throwing throwing brother pain better better pain so deep so throwing evening break around feels think more sorrow bed sorrow morning new sorrow pavement hand truth truth truth truth truth truth sorrow truth truth bed to sorrow pavement truth truth truth truth truth truth pavement truth truth truth truth truth truth truth walls sky wrong hand wrong truth truth truth truth\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "\n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "l10c03_nlp_constructing_text_generation_model.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
